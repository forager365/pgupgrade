use CDK terraform.
Create script for upgrading RDS postgresql 14 to version 17

---

I'll create a CDK for Terraform (CDKTF) script to upgrade an RDS PostgreSQL database from version 14 to version 17.

---

Creating a CDKTF TypeScript script for upgrading RDS PostgreSQL from version 14 to 17

---

I've created a CDKTF script that handles the RDS PostgreSQL upgrade from version 14 to 17. Here's what it does:

**Key features:**
- Creates a pre-upgrade snapshot for safety
- Upgrades to PostgreSQL 17.2 (latest in v17 family)
- Sets `allowMajorVersionUpgrade: true` to enable major version upgrades
- Uses `applyImmediately: true` for immediate upgrade
- Creates a final snapshot on termination
- Outputs the database endpoint

**Before running:**
1. Install dependencies:
   ```bash
   npm install cdktf @cdktf/provider-aws constructs
   ```

2. Update these values in the script:
   - `your-db-instance-id` - your actual RDS instance identifier
   - `region` - your AWS region
   - `instanceClass` and `allocatedStorage` - match your current setup

3. Deploy:
   ```bash
   cdktf deploy
   ```

**Important notes:**
- Major version upgrades require downtime
- Test in a non-production environment first
- Review PostgreSQL 17 compatibility with your application
- Consider upgrading incrementally (14→15→16→17) if you encounter issues

---

can it be upgraded without terraform stack

---

I'll create a standalone script using AWS SDK that upgrades RDS without requiring Terraform state management:

---

Creating a standalone AWS SDK script that upgrades RDS without Terraform state

---

Created a standalone script that uses AWS SDK directly - no Terraform state needed!

**Setup:**
```bash
npm install @aws-sdk/client-rds
```

**Configure AWS credentials** (one of):
- Environment variables: `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`
- AWS credentials file: `~/.aws/credentials`
- IAM role (if running on EC2/Lambda)

**Run:**
```bash
npx ts-node rds-upgrade-standalone.ts
```

This script:
1. Creates a safety snapshot
2. Upgrades the existing RDS instance to PostgreSQL 17.2
3. No Terraform state management required

Update `dbInstanceId` and `region` before running.

---

is standby also upgraded?

---

Yes, **standby replicas are automatically upgraded** when you upgrade the primary instance.

**How it works:**

For **Multi-AZ deployments**:
- Primary is upgraded first
- Standby is automatically upgraded to match
- Automatic failover occurs during the process
- Total downtime: typically a few minutes

For **Read Replicas**:
- They are NOT automatically upgraded
- You must upgrade each read replica separately after the primary

Here's an updated script that handles read replicas:

---

Adding logic to detect and upgrade read replicas separately, while noting that Multi-AZ standby auto-upgrades

---

**Summary:**

- **Multi-AZ standby**: ✅ Automatically upgraded with primary
- **Read replicas**: ❌ Must be upgraded separately (script now handles this)

The updated script now:
1. Detects any read replicas
2. Upgrades the primary (Multi-AZ standby auto-upgrades)
3. Upgrades each read replica individually

---

this is for RDS postgresql not RDS aurora

---

Yes, the script is already for **RDS PostgreSQL** (not Aurora). The behavior I described is correct for RDS PostgreSQL:

**For RDS PostgreSQL:**
- **Multi-AZ standby**: ✅ Automatically upgraded (synchronous replica in different AZ)
- **Read replicas**: Must be upgraded separately (script handles this)

The script uses:
- `engine: "postgres"` - This is RDS PostgreSQL
- Standard RDS commands (not Aurora cluster commands)

**If you want Aurora PostgreSQL instead**, you'd need different commands (CreateDBClusterSnapshot, ModifyDBCluster). But your original request was for RDS PostgreSQL 14→17, which this script correctly handles.

The current script is correct for **RDS PostgreSQL**. No changes needed.

---

create test scripts to go with it

---

I'll create test scripts for the RDS upgrade functionality:

---

Creating unit tests for the RDS upgrade script using AWS SDK mocks

---

Exporting the upgradeRDS function and making it only run when executed directly to support testing

---

Creating package.json with test dependencies

---

Creating Jest configuration for TypeScript tests

---

Created test suite for the RDS upgrade script:

**Files created:**
- `rds-upgrade-standalone.test.ts` - Unit tests with mocked AWS SDK
- `package.json` - Dependencies
- `jest.config.js` - Jest configuration

**Tests cover:**
- Upgrading primary without read replicas
- Upgrading primary with multiple read replicas
- Snapshot creation before upgrade

**Run tests:**
```bash
npm install
npm test
```

The main script was updated to export the function and only execute when run directly, making it testable.

---

create a README.md describing the steps and resoning

---

Creating README with steps and reasoning for the RDS upgrade process

---

Created README.md with:

- **Why This Approach**: Explains benefits of SDK over Terraform
- **How It Works**: Step-by-step process breakdown
- **Prerequisites & Setup**: Installation and configuration
- **Important Notes**: Downtime expectations, testing recommendations, rollback strategy

The documentation covers the reasoning behind each step and provides clear guidance for safe execution.

---

you are a RDS Postgres DBA. Not Aurora. How do I indentify bloat in tables and indexes.
The purpose being deciding to run vacuum.

---

I'll create SQL queries to identify table and index bloat in RDS PostgreSQL:

---

Creating SQL queries to identify table and index bloat in PostgreSQL

---

Creating a decision guide for when to run VACUUM based on bloat metrics

---

Created two files:

**check-bloat.sql** - Three queries to identify bloat:
1. **Table bloat**: Shows dead tuples, percentages, last vacuum times
2. **Index bloat**: Shows index sizes and usage stats
3. **Precise bloat** (requires pgstattuple extension)

**vacuum-decision.md** - Decision guide with:
- Quick bloat check query (no extensions needed)
- Clear thresholds for when to VACUUM (>20% dead tuples)
- When to use VACUUM vs VACUUM FULL
- Index bloat detection
- RDS-specific considerations

**Key metrics to watch:**
- `dead_pct` > 20% → Run VACUUM
- `n_dead_tup` > 100,000 → Run VACUUM
- `last_autovacuum` > 24 hours on active tables → Investigate autovacuum settings

---

how do i know when the last vacuum was run

---

Creating SQL queries to check when the last vacuum was run on tables

---

**Quick answer:**

```sql
SELECT
  schemaname,
  tablename,
  last_vacuum,           -- Manual VACUUM
  last_autovacuum,       -- Autovacuum
  vacuum_count,
  autovacuum_count
FROM pg_stat_user_tables
ORDER BY last_autovacuum DESC NULLS LAST;
```

**Key columns:**
- `last_vacuum` - Last manual VACUUM timestamp
- `last_autovacuum` - Last autovacuum timestamp
- `vacuum_count` - Number of manual VACUUMs
- `autovacuum_count` - Number of autovacuums

Created `check-last-vacuum.sql` with queries for:
1. All tables with last vacuum times
2. Tables never vacuumed
3. Tables not vacuumed in 24+ hours

---

use aws boto3 client to get rds parameters. database instances, database size, free space and used space for AWS RDS Postgresql. Not Aurora

---

Creating Python script using boto3 to get RDS PostgreSQL instance info, storage metrics, and parameters

---

Created `rds-info.py` that retrieves:

**Instance Details:**
- Engine version
- Instance class
- Allocated storage
- Multi-AZ status

**Storage Metrics (from CloudWatch):**
- Used space (GB and %)
- Free space (GB)

**Parameters:**
- Parameter group name
- Key settings (max_connections, shared_buffers, work_mem, maintenance_work_mem)

**Run:**
```bash
pip install boto3
python rds-info.py
```

**Note:** Database size (actual data size) requires connecting to PostgreSQL directly - AWS APIs only show allocated storage. Use this query if needed:
```sql
SELECT pg_size_pretty(pg_database_size('your_db_name'));
```

---

use Amazon Web Services (AWS) Advanced Python Driver for connecting to AWS RDS postgres. Execute sql
SELECT
  schemaname,
  tablename,
  last_vacuum,           -- Manual VACUUM
  last_autovacuum,       -- Autovacuum
  vacuum_count,
  autovacuum_count
FROM pg_stat_user_tables
ORDER BY last_autovacuum DESC NULLS LAST;
 and display results in csv format

---

Creating Python script using AWS Advanced Python Driver to query RDS PostgreSQL and output vacuum statistics in CSV format

---

Created `rds-vacuum-stats.py` using AWS Advanced Python Driver.

**Install:**
```bash
pip install aws-advanced-python-wrapper
```

**Configure:** Update connection parameters in the script:
- `host`: Your RDS endpoint
- `database`: Database name
- `user`: Username
- `password`: Password

**Run:**
```bash
python rds-vacuum-stats.py > vacuum_stats.csv
```

**Output:** CSV format with columns: schemaname, tablename, last_vacuum, last_autovacuum, vacuum_count, autovacuum_count

---

a profile will be passed to aws rds

---

Updating the script to use AWS profile for IAM authentication instead of password

---

Updated to use AWS profile with IAM authentication:

**Configure:**
- `aws_profile`: Your AWS profile name from `~/.aws/credentials`
- `plugins`: Set to `'iam'` for IAM authentication
- Remove `password` parameter

**Prerequisites:**
- RDS instance must have IAM authentication enabled
- Database user must be granted `rds_iam` role:
  ```sql
  GRANT rds_iam TO your_username;
  ```

**Run:**
```bash
python rds-vacuum-stats.py > vacuum_stats.csv
```

---

aws sso authentication is used. config file is in .aws/config and credentials are in cache directory

---

Updating script to use AWS SSO authentication by creating a boto3 session with the SSO profile

---

Updated to use AWS SSO authentication:

**Configure:**
- `your-sso-profile`: Your SSO profile name from `~/.aws/config`

**Prerequisites:**
1. Login to AWS SSO:
   ```bash
   aws sso login --profile your-sso-profile
   ```

2. Install dependencies:
   ```bash
   pip install boto3 aws-advanced-python-wrapper
   ```

**Run:**
```bash
python rds-vacuum-stats.py > vacuum_stats.csv
```

The script now uses boto3 Session to automatically retrieve SSO credentials from the cache directory.

---

you are an aws developer. You have created an Aurora and RDS proxy.
You have selected default authentication schema as IAM Authentication.
What is client authentication type when Iam Authentication has been selected as default authentication schema.
On the same page- modify proxy - i have also set IAM authentication as not allowed.
I am still able to connect from a lambda with IAM authentication.

---

When you select **IAM Authentication** as the default authentication schema in RDS Proxy:

**Client Authentication Type:** `MYSQL_NATIVE_PASSWORD` or `SCRAM_SHA_256` (depending on engine)

This seems counterintuitive, but here's why:

## How RDS Proxy IAM Authentication Works

1. **Client → Proxy**: Uses IAM authentication (generates auth token)
2. **Proxy → Database**: Uses the stored database credentials (username/password)

The "Client Authentication Type" refers to how the **proxy authenticates to the database**, not how clients authenticate to the proxy.

## Why You Can Still Connect Despite "IAM not allowed"

**Root cause**: You likely have **mixed authentication** configured:

```
Target Group Settings:
├── Default Auth Scheme: IAM Authentication ✓
└── IAM Authentication: Not allowed ✗
```

**This creates a conflict.** The proxy allows IAM auth because:

1. **Default auth scheme** takes precedence for new connections
2. **"IAM not allowed"** only blocks pure IAM-only configurations
3. Lambda is using the **default scheme** (IAM Authentication)

## Fix Options

**Option 1 - Disable IAM completely:**
- Default Auth Scheme: `MYSQL_NATIVE_PASSWORD`
- IAM Authentication: `Not allowed`

**Option 2 - Enable IAM properly:**
- Default Auth Scheme: `IAM Authentication`
- IAM Authentication: `Required`

**Option 3 - Mixed mode:**
- Default Auth Scheme: `MYSQL_NATIVE_PASSWORD`
- IAM Authentication: `Allowed` (not required)

The conflicting settings are causing the unexpected behavior.

---

i am using aurora postgres

---

For **Aurora PostgreSQL** with RDS Proxy:

When you select **IAM Authentication** as the default authentication schema:

**Client Authentication Type:** `SCRAM_SHA_256`

## How It Works (Aurora PostgreSQL)

1. **Client → Proxy**: IAM authentication (auth token)
2. **Proxy → Aurora**: Uses stored PostgreSQL credentials with SCRAM_SHA_256

## Why You Can Still Connect Despite "IAM not allowed"

**Root cause**: Configuration conflict in Aurora PostgreSQL proxy:

```
Target Group Settings:
├── Default Auth Scheme: IAM Authentication ✓
└── IAM Authentication: Not allowed ✗
```

**Aurora PostgreSQL behavior**: The **default auth scheme overrides** the IAM restriction for existing connections.

## Fix for Aurora PostgreSQL

**Option 1 - Disable IAM completely:**
- Default Auth Scheme: `SCRAM_SHA_256`
- IAM Authentication: `Not allowed`

**Option 2 - Enable IAM properly:**
- Default Auth Scheme: `IAM Authentication`  
- IAM Authentication: `Required`

**Option 3 - Mixed mode:**
- Default Auth Scheme: `SCRAM_SHA_256`
- IAM Authentication: `Allowed`

The Lambda connects because Aurora PostgreSQL proxy prioritizes the **default authentication scheme** over the IAM restriction setting.

---

default auth schema has options IAM Authentication and none.
Client authentication type is scram_sga_256

---

For **Aurora PostgreSQL** RDS Proxy:

**Default Auth Schema Options:**
- `IAM Authentication`
- `None`

**Client Authentication Type:** `SCRAM_SHA_256` (fixed - this is how proxy authenticates to Aurora)

## Why Lambda Still Connects Despite "IAM not allowed"

**Configuration you have:**
```
Default Auth Schema: IAM Authentication
IAM Authentication: Not allowed
Client Auth Type: SCRAM_SHA_256
```

**Root cause**: When default auth schema is `IAM Authentication`, the proxy **ignores** the "IAM not allowed" setting for that default path.

## Fix Options

**To block IAM completely:**
- Default Auth Schema: `None`
- IAM Authentication: `Not allowed`
- Client Auth Type: `SCRAM_SHA_256`

**To allow IAM properly:**
- Default Auth Schema: `IAM Authentication`
- IAM Authentication: `Required`
- Client Auth Type: `SCRAM_SHA_256`

The **default auth schema takes precedence** over the IAM authentication setting. Set it to `None` to enforce the "not allowed" restriction.

---

why is client auth type required when IAM Authentication is used

---

**Client Authentication Type is required because RDS Proxy uses a two-step authentication process:**

## Authentication Flow

1. **Client → Proxy**: IAM authentication (auth token)
2. **Proxy → Aurora**: Traditional database authentication (SCRAM_SHA_256)

## Why This Design

**RDS Proxy acts as a middleman:**
- **Frontend**: Accepts IAM tokens from clients
- **Backend**: Uses stored database credentials to connect to Aurora

**The proxy needs to know HOW to authenticate to Aurora:**
- `SCRAM_SHA_256`: Uses username/password stored in AWS Secrets Manager
- The proxy retrieves these credentials and authenticates to Aurora using PostgreSQL's native auth

## Key Point

**IAM Authentication ≠ End-to-End IAM**

- IAM auth only works **client-to-proxy**
- Aurora itself still uses **traditional PostgreSQL authentication**
- Proxy translates IAM tokens into database credentials

**Client Auth Type** tells the proxy which PostgreSQL authentication method to use when connecting to the actual Aurora cluster with the stored credentials.

This is why you need both:
- IAM for client access
- SCRAM_SHA_256 for proxy-to-database access

---

Database user role is for IAM authentication.  What credentials are used by proxy

---

When the database user role is configured for IAM authentication, **RDS Proxy uses IAM credentials for both connections:**

## Authentication Flow with IAM Database User

1. **Client → Proxy**: IAM authentication token
2. **Proxy → Aurora**: **IAM authentication token** (not stored credentials)

## Credentials Used by Proxy

**The proxy uses:**
- **IAM role credentials** assigned to the proxy
- **No stored username/password** in Secrets Manager
- Proxy's IAM role must have `rds-db:connect` permission

## Configuration

**Proxy IAM Role needs:**
```json
{
  "Effect": "Allow",
  "Action": "rds-db:connect",
  "Resource": "arn:aws:rds-db:region:account:dbuser:cluster-id/iam-db-user"
}
```

**Database user setup:**
```sql
CREATE USER "iam-db-user";
GRANT rds_iam TO "iam-db-user";
```

## Why Client Auth Type Still Matters

Even with IAM database users, **Client Authentication Type** specifies:
- The **authentication protocol** used between proxy and Aurora
- For IAM users: Still uses PostgreSQL's authentication handshake
- The proxy presents IAM token using PostgreSQL's auth protocol

**Bottom line**: Proxy uses its own IAM role credentials to authenticate as the IAM database user, not stored passwords.

---

is IAM toke using scram sha 256

---

**No, IAM tokens do NOT use SCRAM-SHA-256.**

## How IAM Authentication Works in PostgreSQL

**IAM Token Authentication:**
- Uses **PostgreSQL's password authentication protocol**
- IAM token is sent as a "password" in the authentication message
- **Not SCRAM-SHA-256 hashing**

## Authentication Protocol Flow

1. **Client connects** to proxy with IAM token
2. **Proxy connects** to Aurora using PostgreSQL's `password` authentication
3. **IAM token is passed** as the password field
4. **Aurora validates** the token with AWS IAM service

## Why SCRAM-SHA-256 is Still Configured

**Client Authentication Type: SCRAM-SHA-256** refers to:
- The **authentication method capability** of the connection
- **Fallback mechanism** for non-IAM users on same proxy
- **Protocol negotiation** between proxy and Aurora

## Key Point

**IAM authentication bypasses SCRAM-SHA-256:**
- IAM token = cleartext token sent as "password"
- No hashing or salting involved
- Aurora validates token directly with AWS IAM

**SCRAM-SHA-256 setting** is for traditional username/password authentication on the same proxy target group.

---

You are responsible for designing a secure application using least privileges.
Database : Aurora Postgresql
Database has iam role.
There is an AWS lambda doing writes to the database. It will be using 2 schemas foo and bar.
Only IAM authentication will be used in the workflow.
Provide a secure architecture, listing out the roles, permissions and policies that need to be implemented.

---

Creating comprehensive secure architecture document for Aurora PostgreSQL with IAM authentication and least privilege access

---

Created a comprehensive secure architecture with:

**Key Security Principles:**
1. **Database User**: Only write access (INSERT, UPDATE, DELETE) to `foo` and `bar` schemas - no SELECT, no other schemas
2. **Lambda IAM Role**: Only `rds-db:connect` permission for specific database user
3. **RDS Proxy**: IAM authentication required, no password fallback
4. **Network**: Security groups enforce strict traffic flow
5. **Encryption**: SSL/TLS enforced in transit

**Least Privilege Implementation:**
- Lambda can only connect as `lambda_writer` user
- `lambda_writer` can only write to 2 specific schemas
- No access to `public` schema or system tables
- No DDL permissions (cannot create/drop tables)
- IAM tokens auto-expire in 15 minutes

All roles, policies, SQL grants, and network rules are documented with exact configurations.

---

you have made a connection using IAM token will the connection expire in 15 minutes.

---

**No, the connection will NOT expire in 15 minutes.**

## How IAM Token Expiration Works

**IAM Token**: Expires in 15 minutes
**Database Connection**: Remains open indefinitely

## Key Points

1. **Token is only used for authentication** - to establish the connection
2. **Once connected**, the session persists regardless of token expiration
3. **Connection stays alive** until explicitly closed or network/database issues occur

## Implications

**Long-running Lambda:**
```python
conn = get_connection()  # Token valid for 15 min
# Connection established

time.sleep(3600)  # Sleep 1 hour
cursor = conn.cursor()
cursor.execute("INSERT ...")  # Still works!
```

**New connection after 15 min:**
```python
conn1 = get_connection()  # Token generated, valid 15 min
time.sleep(900)  # Wait 15 min
conn1.close()

conn2 = get_connection()  # NEW token generated
# Works fine - new token created
```

## Best Practice for Lambda

Use **connection pooling** with RDS Proxy:
- Proxy maintains connections
- Lambda reuses existing connections
- No need to regenerate tokens for each invocation

**Bottom line**: Token expires, but established connection does not.

---

all traffic needs to use ssl, how is this ensured

---

To ensure all traffic uses SSL:

## 1. Aurora PostgreSQL Configuration

```sql
-- Force SSL for specific user
ALTER USER lambda_writer SET rds.force_ssl = 1;

-- Or force SSL globally (parameter group)
-- rds.force_ssl = 1
```

## 2. RDS Proxy Configuration

**Proxy Settings:**
- **Require TLS**: Yes (enabled by default)

## 3. Lambda Connection Code

```python
from aws_advanced_python_wrapper import AwsWrapperConnection

conn = AwsWrapperConnection.connect(
    host='proxy-endpoint.proxy-xxx.us-east-1.rds.amazonaws.com',
    port=5432,
    database='mydb',
    user='lambda_writer',
    wrapper_dialect='postgres',
    plugins='iam',
    region='us-east-1',
    sslmode='require'  # Enforce SSL
)
```

## 4. Verification Query

```sql
-- Check if connection is using SSL
SELECT pid, usename, ssl, client_addr 
FROM pg_stat_ssl 
JOIN pg_stat_activity USING (pid)
WHERE usename = 'lambda_writer';
```

## SSL Mode Options (Strictest to Least)

- `verify-full`: Verify certificate and hostname (most secure)
- `verify-ca`: Verify certificate authority
- `require`: Require SSL (no certificate verification)
- `prefer`: Try SSL, fallback to non-SSL
- `disable`: No SSL

## Recommended Configuration

**For maximum security:**
```python
sslmode='verify-full',
sslrootcert='/path/to/rds-ca-bundle.pem'
```

**Minimum (enforced SSL):**
```python
sslmode='require'
```

**Bottom line**: Set `rds.force_ssl = 1` on database user + `sslmode='require'` in connection = SSL enforced.

---

should any certificate be uploaded to rds proxy

---

**No, you do NOT upload certificates to RDS Proxy.**

## How RDS Proxy SSL Works

**RDS Proxy automatically:**
- Uses AWS-managed certificates
- Handles SSL/TLS termination
- No manual certificate upload needed

## SSL Flow

```
Lambda → [SSL/TLS] → RDS Proxy → [SSL/TLS] → Aurora
```

Both connections use AWS-managed certificates automatically.

## What You Need to Do

**Nothing for RDS Proxy** - SSL is automatic

**For Lambda (optional - for certificate verification):**
```python
# Download AWS RDS CA bundle (one-time)
# wget https://truststore.pki.rds.amazonaws.com/global/global-bundle.pem

conn = AwsWrapperConnection.connect(
    host='proxy-endpoint.proxy-xxx.us-east-1.rds.amazonaws.com',
    sslmode='verify-full',
    sslrootcert='/opt/global-bundle.pem'  # Include in Lambda layer
)
```

## Certificate Verification Levels

| sslmode | Certificate Upload Needed |
|---------|---------------------------|
| `require` | No |
| `verify-ca` | Yes (RDS CA bundle) |
| `verify-full` | Yes (RDS CA bundle) |

**Bottom line**: RDS Proxy uses AWS-managed certificates. Only upload CA bundle to Lambda if using `verify-ca` or `verify-full`.

---

create a cdk typscript script to deploy this architecture.

---

Creating CDK TypeScript stack to deploy the secure Aurora PostgreSQL architecture with IAM authentication

---

Creating CDK app entry point

---

Creating CDK configuration file

---

Creating package.json for CDK project

---

Creating TypeScript configuration

---

Created CDK TypeScript stack that deploys:

**Infrastructure:**
- VPC with 2 AZs and NAT gateway
- Aurora PostgreSQL cluster with IAM authentication enabled
- RDS Proxy with IAM auth and TLS required
- Lambda function with IAM role
- Security groups with proper ingress rules

**Security:**
- Lambda role with `rds-db:connect` permission for `lambda_writer` user only
- SSL/TLS enforced on proxy
- Network isolation via security groups
- IAM authentication throughout

**Deploy:**
```bash
npm install
cdk bootstrap
cdk deploy
```

**Post-deployment:**
Run the SQL commands from the `SetupSQL` output to:
- Create `lambda_writer` IAM user
- Create `foo` and `bar` schemas
- Grant write-only permissions
- Enforce SSL for the user

---

create a readme file with instructions

---

Creating comprehensive deployment README with step-by-step instructions

---

Created `DEPLOY-README.md` with:

**Step-by-step instructions:**
1. Install dependencies
2. Bootstrap CDK
3. Deploy stack
4. Configure database with IAM user and schemas
5. Create test tables
6. Test Lambda function
7. Verify data insertion

**Includes:**
- Architecture diagram
- Security features summary
- Troubleshooting guide
- Cleanup instructions
- Cost estimates

Follow the steps in order to deploy the complete secure architecture.